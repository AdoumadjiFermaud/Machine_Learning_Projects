# Machine_Learning_Projects


DecisionTreeClassifier est capable de gérer des problèmes de classification à plusieurs classes (par exemple, avec les étiquettes 0, 1, … K-1). Dans cet exemple nous allons travailler avec la base de données Iris, facilement accessible dans sklearn. Cette base contient 150 instances d’iris (un type de plante, chaque observation décrit sa morphologie). L’objectif est de classer chaque instance en une des trois catégories : Iris setosa, Iris virginica ou Iris versicolor.

Une des classes est linéairement séparable par rapport aux deux autres, mais les deux autres ne sont pas séparables une par rapport à l’autre.

Les attributs du jeu de données sont :

    longueur de sépale,

    largeur de sépale,

    longueur de pétale,

    largeur de pétale,

    classe : Iris Setosa, Iris Versicolor ou Iris Virginica.

Un échantillon : (4.9,3.6,1.4,0.1, “Iris-setosa”)

Par exemple, les experts en fleurs savent que les iris Setosa ont de petits pétales. Cette règle peut également être déduite en examinant les données. Si nous regardons la distribution des mesures des sépales et des pétales pour les différentes espèces d'iris, nous pouvons voir que la longueur et la largeur des pétales distinguent bien les Setosa. Mais comment gérer des données plus complexes et plus nombreuses ? L'avantage du machine learning est qu'il automatise la création des règles à partir des données, y compris leurs détails, par exemple où définir exactement le seuil sur la longueur des pétales. Concrètement, le machine learning construit les règles de prédiction à partir des données. Nous allons maintenant entrer dans le vif du sujet en nous concentrant sur les modèles prédictifs. Pour créer des modèles prédictifs, nous allons nous appuyer sur les propriétés statistiques des données. Cependant, les questions et les outils que nous utiliserons diffèrent un peu de ceux traditionnellement utilisés en statistique. En machine learning, nous voulons conclure sur de nouvelles instances. Dans l'exemple du recensement, je veux pouvoir prédire le revenu des nouveaux individus, avec une combinaison d'emplois et de données démographiques que je n'ai jamais vues. Le défi est qu'un individu peut varier de plusieurs façons, même dans le cadre de la description limitée qu'affichent nos données. Une difficulté supplémentaire est le bruit dans les données. Par bruit, nous entendons les aspects qui ne peuvent être expliqués uniquement à partir des données. Par exemple, le revenu d'un individu peut avoir été influencé par l'humeur de son manager lors de son examen annuel, ce qui ne figure pas dans notre base de données. Une possibilité pour prédire est de mémoriser toutes les données disponibles. Dans le cas de la prédiction du revenu, nous pouvons enregistrer tous les individus connus du recensement. Puis, pour un nouvel individu, nous prédisons le revenu selon la correspondance la plus proche dans notre base de données. Cette stratégie est connue en machine learning comme un prédicteur du "plus proche voisin". Si nous essayons cette stratégie sur les données dont nous disposons, le recensement, quel taux d'erreur pouvons-nous attendre ? Chaque individu pour lequel nous demandons une prédiction est dans notre base de données. Ainsi, sa correspondance la plus proche sera elle-même, et par conséquent, nous n'aurons aucune erreur de prédiction. Cependant, si nous essayons notre stratégie sur de nouvelles données nous ne pourrons pas trouver une correspondance exacte. Par conséquent, des erreurs peuvent se produire. Ce que nous voyons ici, c'est que la généralisation est très différente de la mémorisation. C'est un défi fondamental en machine learning. La raison en est que les données sur lesquelles nous avons appliqué le modèle prédictif, appelées données de test, sont différentes des données utilisées pour créer le modèle prédictif, appelées données d'entraînement. Elles sont différentes parce qu'il peut y avoir des bruits différents, mais aussi parce qu'il peut y avoir des individus avec de nouvelles configurations de caractéristiques que nous n'avons pas observées : différentes combinaisons de profession, d'âge ou d'état civil. Le process typique du machine learning consiste à utiliser un ensemble de données spécifique pour apprendre un modèle prédictif comme par exemple, prédire l'espèce d'iris. Puis l'appliquer à de nouvelles données ou ce que nous appellerons un ensemble de test, pour mettre le modèle en production, ou pour vérifier sa validité. Pour aller plus loin, il est utile de définir un peu les concepts de l'apprentissage statistique. Toutes les données que nous aller considérer seront dans ce que nous appelons une matrice de données. Cela peut être vu comme décrivant notre problème dans un tableau 2D. Les différentes lignes de ce tableau sont des observations différentes, par exemple, des iris différents. Nous les appelons des échantillons. Les colonnes de ce tableau donnent les différentes mesures ou descripteurs que nous avons pour ces différents échantillons. Nous les appelons des caractéristiques. Dans l'apprentissage supervisé, les données dont nous disposons sont annotées. En d'autres termes, elles sont associées à un libellé ou à une classe cible. Pour les iris, chaque point de données est associé à une espèce d'iris : notre classe cible. Le but de l'apprentissage supervisé est de prédire cette classe cible, ici, l'espèce d'iris, sur de nouvelles données sans annotation, en n'entrant que les dimensions des pétales et sépales. En termes mathématiques, pour l'apprentissage supervisé, on a une matrice de données que nous noterons X avec n observations. Et une cible Y, qui donne une caractéristique pour chaque observation. L'objectif de l'apprentissage supervisé est de prédire Y à partir de X. Dans l'apprentissage non supervisé, on a la matrice de données X, mais nous n'avons pas de cible disponible. Le but est alors d'extraire une sorte de structure de X qui se généralise à de nouvelles données. Si nous prenons l'exemple des iris, en apprentissage non supervisé, les données d'entrée n'incluent pas l'espèce d'iris car les données ne sont pas annotées. L'objectif est donc de trouver des similitudes et des structures au sein des données ou de regrouper des observations partageant des caractéristiques communes. L'apprentissage non supervisé couvre une grande variété de problèmes différents. Nous ne les traiterons pas ici. Pour en revenir à l'apprentissage supervisé, nous devons prédire la cible Y. Cette cible est une propriété de nos données. Elle peut être discrète, décrivant différentes classes de données. Par exemple, avec les iris, nous essayons de prédire l'espèce d'iris. Dans une telle situation, on dit que c'est une tâche de classification. Elle peut aussi être continue, décrivant une propriété numérique de notre observation. Par exemple, en essayant de prédire à partir du recensement qui est riche, il serait intéressant de prédire le revenu en dollars. Dans une telle situation, on dit que c'est une tâche de régression. Pour résumer, le machine learning consiste à extraire, à partir des données, des règles qui se généralisent à de nouvelles observations. En pratique, nous travaillons avec la matrice de données que nous appellons X, avec n_samples lignes fois n_features colonnes. Pour l'apprentissage supervisé, nous avons un vecteur cible Y, de longueur n_samples, qui est constitué de nombres caractérisant chaque observation pour les problèmes de régression et des classes discrètes pour les problèmes de classification.
